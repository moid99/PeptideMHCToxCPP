# -*- coding: utf-8 -*-
"""ToxicityPredictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13tcsDqQmnBia4KyHHmM2pej33mqQMzoo
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim

feature_csv = pd.read_csv('peptide_features.csv', header=None)
feature_array = np.asarray(feature_csv)
X = torch.FloatTensor(feature_array)
print(X)

class binaryClassification(nn.Module):
    def __init__(self):
        super(binaryClassification, self).__init__()
        # Number of input features is 12.
        self.layer_1 = nn.Linear(1024, 512) 
        self.layer_2 = nn.Linear(512, 16)
        self.layer_out = nn.Linear(16, 1) 
        
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(p=0.5)
        self.batchnorm1 = nn.BatchNorm1d(512)
        self.batchnorm2 = nn.BatchNorm1d(16)
        
    def forward(self, inputs):
        x = self.relu(self.layer_1(inputs))
        x = self.batchnorm1(x)
        x = self.relu(self.layer_2(x))
        x = self.batchnorm2(x)
        x = self.dropout(x)
        x = self.layer_out(x)
        
        return x

def load_checkpoint(filepath):
    checkpoint = torch.load(filepath)
    model = checkpoint['model']
    model.load_state_dict(checkpoint['state_dict'])
    for parameter in model.parameters():
        parameter.requires_grad = False
    
    model.eval()
    
    return model

model = load_checkpoint('ToxicityModel.pth')

for value in X:
  prediction = model(value[None,...])
  pred_sig = torch.sigmoid(prediction)
  pred_rd = torch.round(pred_sig)
  answer = pred_rd.item()
  if answer == 0:
    print('non-toxic')
  else:
    print('toxic')